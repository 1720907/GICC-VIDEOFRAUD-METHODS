{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8526908,"sourceType":"datasetVersion","datasetId":5091176},{"sourceId":8607445,"sourceType":"datasetVersion","datasetId":5111549},{"sourceId":10005122,"sourceType":"datasetVersion","datasetId":6158500}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\n# pred_labels = np.unique()\n# labels = [\"Original\",\"Inserted\", \"Deleted\"]\n# labels_to_show = [labels[label] for label in pred_labels]\nnombre_dataset = \"video-fraud-results\"\n\ndef show_report_p2(fold, dataset):\n    vfd_pred = np.load(f\"/kaggle/input/{nombre_dataset}/P2/{dataset}/vfd_y_pred_fold_{fold}.npy\")\n    vfd_test = np.load(f\"/kaggle/input/{nombre_dataset}/P2/{dataset}/vfd_y_test_fold_{fold}.npy\")\n    pred_labels = np.unique(vfd_pred)\n    return classification_report(vfd_test, vfd_pred, labels = pred_labels, output_dict=True, zero_division=0)\n\ndef show_report_p1(fold, dataset):\n    y_pred = np.load(f\"/kaggle/input/{nombre_dataset}/P1-10epochs/{dataset}/y_pred_fold_{fold}.npy\")\n    y_test = np.load(f\"/kaggle/input/{nombre_dataset}/P1-10epochs/{dataset}/y_test_fold_{fold}.npy\")\n    return classification_report(y_test, y_pred, output_dict=True, zero_division=0)\ndef find_metrics(n_folds, dataset, function):\n    precision = []\n    recall = []\n    f1 = []\n    acc = []\n    for i in range(n_folds):\n        report = function((i+1),dataset)\n        precision.append(report['macro avg']['precision'])\n        recall.append(report['macro avg']['recall'])\n        f1.append(report['macro avg']['f1-score'])\n        acc.append(report['accuracy'])\n    mean_precision = np.mean(precision)\n    mean_recall = np.mean(recall)\n    mean_f1 = np.mean(f1)\n    mean_acc = np.mean(acc)\n    # Mostrar los resultados\n    print(f\"Results {dataset}: \", end=' ')\n    \n    print(f'Mean Precision (Macro Avg): {mean_precision:.2f}', end=' ')\n    print(f'Mean Recall (Macro Avg): {mean_recall:.2f}', end=' ')\n    print(f'Mean F1-Score (Macro Avg): {mean_f1:.2f}')\n    print(f\"Mean Accuracy: {mean_acc:.2f}\")\n    \ndataset_dict = ['D1','D2','D3','D1D2','D1D3','D2D3','D1D2D3'] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:59:02.157240Z","iopub.execute_input":"2024-11-25T04:59:02.157703Z","iopub.status.idle":"2024-11-25T04:59:02.169000Z","shell.execute_reply.started":"2024-11-25T04:59:02.157646Z","shell.execute_reply":"2024-11-25T04:59:02.167744Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Data\ndatasets = ['D1', 'D2', 'D3', 'D1+D2', 'D1+D3', 'D2+D3', 'D1+D2+D3']\nmetrics = ['Precision', 'Recall', 'F1', 'Accuracy']\n\np1 = {\n    'Precision': [0.87, 0.46, 0.49, 0.88, 0.88, 0.48, 0.90],\n    'Recall': [0.78, 0.50, 0.50, 0.79, 0.77, 0.50, 0.76],\n    'F1': [0.81, 0.48, 0.49, 0.83, 0.81, 0.49, 0.81],\n    'Accuracy': [0.94, 0.93, 0.98, 0.95, 0.95, 0.97, 0.95]\n}\n\np2 = {\n    'Precision': [0.41, 0.33, 0.14, 0.43, 0.42, 0.31, 0.43],\n    'Recall': [0.34, 0.27, 0.06, 0.35, 0.35, 0.16, 0.36],\n    'F1': [0.35, 0.27, 0.09, 0.36, 0.36, 0.21, 0.36],\n    'Accuracy': [0.51, 0.37, 0.14, 0.53, 0.53, 0.25, 0.53]\n}\n\nx = np.arange(len(datasets))\nwidth = 0.35\n\n# Plotting\nfig, ax = plt.subplots(2, 2, figsize=(14, 10))\nax = ax.flatten()\n\nfor i, metric in enumerate(metrics):\n    ax[i].bar(x - width/2, p1[metric], width, label='P1')\n    ax[i].bar(x + width/2, p2[metric], width, label='P2')\n    ax[i].set_title(metric)\n    ax[i].set_xticks(x)\n    ax[i].set_xticklabels(datasets)\n    ax[i].legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_p2(fold, dataset):\n    vfd_pred = np.load(f\"/kaggle/input/video-fraud-results/P2/{dataset}/vfd_y_pred_fold_{fold}.npy\")\n    vfd_test = np.load(f\"/kaggle/input/video-fraud-results/P2/{dataset}/vfd_y_test_fold_{fold}.npy\")\n    return vfd_pred, vfd_test\ndef get_p1(fold, dataset):\n    y_pred = np.load(f\"/kaggle/input/video-fraud-results/P1-100epochs/{dataset}/y_pred_fold_{fold}.npy\")\n    y_test = np.load(f\"/kaggle/input/video-fraud-results/P1-100epochs/{dataset}/y_test_fold_{fold}.npy\")\n    return y_pred, y_test\ndef get_y_pred_y_test(n_folds, dataset, function):\n    y_pred = np.array([], dtype=np.uint8)\n    y_test = np.array([], dtype=np.uint8)\n    for i in range(n_folds):\n        output1, output2 = function((i+1),dataset)\n        y_pred = np.append(y_pred, output1)\n        y_test = np.append(y_test, output2)\n    return y_pred, y_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print('Resultados P1: ')\n# for element in dataset_dict:\n#     find_metrics(10, element, show_report_p1)\n# print('-----------------------------------------------------------------------------------------------------------------')\n# print('Resultados P2: ')\n# for element in dataset_dict:\n#     find_metrics(10, element, show_report_p2)\n\nfind_metrics(10,\"D3\",show_report_p2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:59:13.061292Z","iopub.execute_input":"2024-11-25T04:59:13.061694Z","iopub.status.idle":"2024-11-25T04:59:13.226382Z","shell.execute_reply.started":"2024-11-25T04:59:13.061648Z","shell.execute_reply":"2024-11-25T04:59:13.225327Z"}},"outputs":[{"name":"stdout","text":"Results D3:  Mean Precision (Macro Avg): 0.63 Mean Recall (Macro Avg): 0.61 Mean F1-Score (Macro Avg): 0.60\nMean Accuracy: 0.61\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# import matplotlib as plt\n\n\n# def show_matrix(fold):\n#     vfc_pred = np.load(f\"/kaggle/input/just-a-test/vfc_y_pred_fold_{fold}.npy\")\n#     vfc_test = np.load(f\"/kaggle/input/just-a-test/vfc_y_test_fold_{fold}.npy\")\n    \n#     pred_labels = np.unique(vfc_pred)\n#     labels = [\"Original\",\"Inserted\", \"Deleted\"]\n#     labels_to_show = [labels[label] for label in pred_labels]\n#     print(f'{labels_to_show}')\n#     cnf2_matrix = confusion_matrix(vfc_test, vfc_pred, labels = pred_labels)\n#     plt.style.use('dark_background')\n#     disp=ConfusionMatrixDisplay(confusion_matrix= cnf2_matrix, display_labels = labels_to_show)\n#     disp.plot()\n\n# show_matrix(4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ----------------------------------------------------------------------------------------------------------\n# P-VALUE","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# from sklearn.model_selection import train_test_split\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.metrics import accuracy_score\n# from scipy.stats import ttest_rel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# threshold=0.05\n# for element in dataset_dict:\n#     print(\"Dataset: \", element)\n#     y_pred_p1, y_test_p1 = get_y_pred_y_test(10, element, get_p1)\n#     y_pred_p2, y_test_p2 = get_y_pred_y_test(10, element, get_p2)\n#     if np.array_equal(y_test_p1, y_test_p2)==False:\n#         print(\"Not comparable models because of the y_pred\")\n#         break\n#     t_estadistico, p_value = ttest_rel(y_pred_p1, y_pred_p2)\n#     if p_value <= threshold:\n#         print(\"Hip贸tesis nula rechazada\")\n#         print(\"Hip贸tesis alternativa (H1) es que hay una diferencia significativa\")\n#     else:\n#         print(\"Hip贸tesis nula NO rechazada\")\n#         print(\"Hip贸tesis nula (H0) es que no hay diferencia significativa entre los modelos\")\n#     print(\"---------------------------------------------------------------------------------\")\n    \n        \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}