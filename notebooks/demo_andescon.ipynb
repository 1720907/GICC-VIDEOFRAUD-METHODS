{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a0a72d-030c-4bca-9d08-4b448cb3e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctinipuclla\\AppData\\Local\\miniconda3\\envs\\demo_env\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "#Global imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os.path import isfile, join, basename, dirname\n",
    "#For P1\n",
    "from keras.models import load_model\n",
    "#For P2\n",
    "import tensorflow as tf\n",
    "from scipy.stats import pearsonr\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8433d66e-6703-451c-af05-ba03323b7ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ctinipuclla\\AppData\\Local\\miniconda3\\envs\\demo_env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\ctinipuclla\\AppData\\Local\\miniconda3\\envs\\demo_env\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118d9f5c-b2e4-4eaa-9055-814e911c5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for P1\n",
    "def resize_frames_single(list_frames, target_size=(64,64)):\n",
    "  resized_frames = [cv2.resize(frame, target_size, interpolation=cv2.INTER_AREA) for frame in list_frames]\n",
    "  return resized_frames\n",
    "def frame_difference_single(processed_frames):\n",
    "  differences_video = []\n",
    "  for j in range(len(processed_frames)-1):\n",
    "    diff = cv2.absdiff(processed_frames[j], processed_frames[j+1])\n",
    "    differences_video.append(diff)\n",
    "  differences_video = np.array(differences_video)\n",
    "  return differences_video\n",
    "def generate_frame_batches_single(difference_frames, batch_size=36):\n",
    "  batches = []\n",
    "\n",
    "  n_frames = len(difference_frames)\n",
    "  for start in range(0, n_frames, batch_size):\n",
    "    end = start + batch_size\n",
    "    # Ensure the batch has the required batch_size, otherwise fill with zeros\n",
    "    if end <= n_frames:\n",
    "      batch = difference_frames[start:end]\n",
    "    else:\n",
    "      # If there are not enough frames left for a full batch, fill the remainder with zeros\n",
    "      remainder = end - n_frames\n",
    "      batch = np.vstack((difference_frames[start:n_frames], np.zeros((remainder, difference_frames.shape[1], difference_frames.shape[2], difference_frames.shape[3]), dtype=difference_frames.dtype)))\n",
    "    batches.append(batch)\n",
    "  return batches\n",
    "\n",
    "#Functions for P2\n",
    "#Model for feature extraction\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', strides=2))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', strides=2))\n",
    "    model.add(MaxPooling2D((3, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8192, activation='relu')) # andescon\n",
    "    return model\n",
    "\n",
    "#Extract features\n",
    "def extract_features_batch(model, frames_batch):\n",
    "    frames_reshaped = np.array(frames_batch).reshape((len(frames_batch), frames_batch[0].shape[0], frames_batch[0].shape[1], 1))\n",
    "    features_batch = model.predict(frames_reshaped, verbose=0)\n",
    "    return features_batch\n",
    "\n",
    "#R: Pearson correlation coefficient f.\n",
    "def calculate_r(features1, features2):\n",
    "    r, _ = pearsonr(features1, features2)\n",
    "    if r == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return r\n",
    "\n",
    "#Rs: Difference of the adjacent correlation coefficients f.\n",
    "def calculate_rs(r_video):\n",
    "    rs_video = np.abs(np.diff(r_video, n=1))\n",
    "    return np.insert(rs_video, 0, 0)\n",
    "\n",
    "#Sod: Second-order derivative f.\n",
    "def calculate_sod(differences):\n",
    "    n = len(differences)\n",
    "    second_deriv = np.zeros_like(differences)  # Initialize with zeros\n",
    "    for x in range(1, n-1):\n",
    "        second_deriv[x] = differences[x+1] + differences[x-1] - (2*differences[x])\n",
    "    second_deriv[0] = 0  # Setting boundary conditions based on your specific needs\n",
    "    if n > 1:\n",
    "        second_deriv[-1] = 0\n",
    "    return second_deriv #np.diff(differences, n=2)\n",
    "\n",
    "# Video forgery detection f. -- andescon\n",
    "def vf_detection(rs_video, lambda_t):\n",
    "    return np.array(rs_video) > lambda_t\n",
    "\n",
    "# VFD-video result -- andescon\n",
    "def get_vfd_output(vfd_list):\n",
    "    for i in range(vfd_list.size):\n",
    "        if(vfd_list[i] == True):\n",
    "            vfd_list[i] = 1 \n",
    "        else:\n",
    "            vfd_list[i] = 0\n",
    "    return vfd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ebb3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a8698c96c341d69e0dae9c13c5dffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Cargar video')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39112b99324947be8dc7527c364b0794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513a883b780545ea8786892b4541543b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Ejecutar P1', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1acef18c12449e9cda5438287b7d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Ejecutar P2', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94da2779dc5c4f10a17bb57f659dbad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For interfaces\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Video\n",
    "import os\n",
    "\n",
    "#For preprocessing and models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_video(video_filename, method, frame_size=(250, 250)):\n",
    "    cap = cv2.VideoCapture(video_filename)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_filename}\")\n",
    "        return None\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "    \n",
    "    if method == 2:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # to grayscale\n",
    "            resized_frame = cv2.resize(gray_frame, frame_size) # resize the frame\n",
    "            frames.append(resized_frame)\n",
    "        \n",
    "        cap.release() # release the video capture object\n",
    "        frames_array = np.array(frames)\n",
    "    else:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "        video_frames = np.array(frames)\n",
    "        cap.release()\n",
    "        #resize\n",
    "        processed_frames = resize_frames_single(video_frames, frame_size)\n",
    "        #difference\n",
    "        difference_frames = frame_difference_single(processed_frames)\n",
    "        #normalization\n",
    "        difference_frames = difference_frames.astype('float32')/255\n",
    "        #batches of 36 frames\n",
    "        video_frame_batches = generate_frame_batches_single(difference_frames, batch_size = 36)\n",
    "        video_frame_batches = np.array(video_frame_batches)\n",
    "        frames_array = video_frame_batches\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        print(\"Warning: No frames were extracted from the video.\")\n",
    "        return None\n",
    "    \n",
    "    return frames_array\n",
    "\n",
    "# Crear widgets\n",
    "upload_button = widgets.FileUpload(description=\"Cargar video\")\n",
    "output_video = widgets.Output()\n",
    "run_p1_button = widgets.Button(description=\"Ejecutar P1\")\n",
    "run_p2_button = widgets.Button(description=\"Ejecutar P2\")\n",
    "result_output = widgets.Output()\n",
    "\n",
    "# Función para mostrar el video cargado\n",
    "def on_upload_change(change):\n",
    "    with output_video:\n",
    "        output_video.clear_output()\n",
    "        # Elimina el archivo anterior si existe\n",
    "        if hasattr(on_upload_change, 'last_video_filename'):\n",
    "            if os.path.exists(on_upload_change.last_video_filename):\n",
    "                try:\n",
    "                    os.remove(on_upload_change.last_video_filename)\n",
    "#                     print(f\"Archivo anterior {on_upload_change.last_video_filename} eliminado.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al eliminar el archivo anterior: {str(e)}\")\n",
    "\n",
    "        for file_info in upload_button.value:\n",
    "            video_data = file_info['content']\n",
    "            video_filename = file_info['name']\n",
    "            \n",
    "#             print(f\"Tamaño del archivo: {len(video_data)} bytes\")\n",
    "            \n",
    "            with open(video_filename, 'wb') as f:\n",
    "                f.write(video_data)\n",
    "            \n",
    "            if os.path.exists(video_filename):\n",
    "                print(f\"Video guardado y listo para procesar: '{video_filename}', con peso: {os.path.getsize(video_filename)/1000000} MB\")\n",
    "            else:\n",
    "                print(f\"Error: el archivo {video_filename} no fue guardado correctamente.\")\n",
    "                \n",
    "            run_p2_action.video_filename = video_filename  # Guardar el nuevo nombre para run_p2_action\n",
    "            run_p1_action.video_filename = video_filename  # Guardar el nuevo nombre para run_p1_action\n",
    "            on_upload_change.last_video_filename = video_filename  # Guardar el nombre del último archivo\n",
    "\n",
    "            try:\n",
    "                display(Video(video_filename, width=600, height=400))\n",
    "#                 print(\"Video mostrado correctamente.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error mostrando el video: {str(e)}\")\n",
    "\n",
    "upload_button.observe(on_upload_change, names='value')\n",
    "\n",
    "# Funciones para ejecutar los modelos P1 y P2\n",
    "def run_p1_action(b):\n",
    "    with result_output:\n",
    "        result_output.clear_output()\n",
    "        # Aquí deberías llamar a tu función para ejecutar el modelo P1\n",
    "        # Por ejemplo, podrías tener algo como:\n",
    "        # result = model_P1(video_filename)\n",
    "        if not hasattr(run_p1_action, 'video_filename'):\n",
    "            print(\"Error: No video file available for processing.\")\n",
    "            return\n",
    "        print(f\"Ejecutando clasificación P1\")\n",
    "        video_filename = run_p1_action.video_filename\n",
    "        video_frame_batches = preprocess_video(video_filename,1,(64,64))\n",
    "        predictions = model.predict(video_frame_batches)\n",
    "        predictions = predictions.reshape((-1))\n",
    "        prediction = \"\"\n",
    "        for i in range(predictions.shape[0]):\n",
    "            if predictions[i]>0.5:\n",
    "                predictions[i] = 1\n",
    "            else:\n",
    "                predictions[i] = 0\n",
    "        if any(l==1 for l in predictions):\n",
    "            forged_ind = np.where(predictions == 1)[0]\n",
    "            prediction=f\"El video es manipulado, en el segundo {forged_ind[0]/30} aproximadamente\"\n",
    "        else:\n",
    "            prediction = \"Video es original\"\n",
    "        print(prediction)\n",
    "     \n",
    "def run_p2_action(b):\n",
    "    with result_output:\n",
    "        result_output.clear_output()\n",
    "        \n",
    "        # Assuming the video filename was saved during the upload\n",
    "        if not hasattr(run_p2_action, 'video_filename'):\n",
    "            print(\"Error: No video file available for processing.\")\n",
    "            return        \n",
    "        video_filename = run_p2_action.video_filename\n",
    "        \n",
    "        # Preprocess the video\n",
    "        frames_array = preprocess_video(video_filename, 2)\n",
    "        if frames_array is not None:\n",
    "            print(f\"Fueron procesados {frames_array.shape[0]} frames.\")\n",
    "            print(f\"Ejecutando clasificación P2\")\n",
    "            #Execution\n",
    "            r_videos = [] #PCC from video\n",
    "            model = build_cnn(input_shape=(250, 250, 1)) #defining model\n",
    "            \n",
    "            features_batch = extract_features_batch(model, frames_array)\n",
    "                    \n",
    "            correlations = [calculate_r(features_batch[i], features_batch[i+1]) for i in range(len(frames_array)-1)]\n",
    "#             r_videos.append(correlations)\n",
    "            rs_video = calculate_rs(correlations)\n",
    "#             print(f\"Frame differences: {rs_video}\")\n",
    "            \n",
    "            vfd_list = vf_detection(rs_video, 0.0085) #lambda value\n",
    "#             print(f\"VFD list: {vfd_list}\")\n",
    "            \n",
    "            predictions = get_vfd_output(vfd_list)\n",
    "            if any(l==1 for l in predictions):\n",
    "                forged_ind = np.where(predictions == 1)[0]\n",
    "                prediction=f\"El video es manipulado, en el segundo {forged_ind[0]/30} aproximadamente\"\n",
    "            else:\n",
    "                prediction = \"Video es original\"\n",
    "        else:\n",
    "            result = \"Error processing the video.\"\n",
    "        print(prediction)\n",
    "\n",
    "frames_arraysito = run_p2_action\n",
    "    \n",
    "run_p1_button.on_click(run_p1_action)\n",
    "run_p2_button.on_click(run_p2_action)\n",
    "\n",
    "# Mostrar widgets en la interfaz\n",
    "display(upload_button)\n",
    "display(output_video)\n",
    "display(run_p1_button, run_p2_button)\n",
    "display(result_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a74bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:demo_env] *",
   "language": "python",
   "name": "conda-env-demo_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
